---
title: "Regression Battleship - Creating your Data"
author: "Jim Greene and Brent Rawlins"
output: 
  html_document:
    theme: cerulean
---

## Creating your Data

Remember the rules...

### Rules

1. Your csv must contain 11 columns of data.
    * The first column must be your (1) Y-variable (labeled as "Y").
    * The other ten columns must be (10) X-variables (labeled as "X6", "X10", ... , "X5").
    
2. Your Y-variable (or some transformation of the Y-variable) must have been created from a linear regression model using only X-variables (or transformations of those X-variables) from within your data set.
    * Be very careful with transformations. You must ensure that you do not break the rules of a linear regression if you choose to use transformations.
    * If you choose transformations, only these functions are allowed when transforming X and Y variables: 1/Y^2, 1/Y, log(Y), sqrt(Y), Y^2, Y^3, 1/X^2, 1/X, log(X), sqrt(X), X^2, X^3, X^4, X^5. Don't forget to check Rule #3 carefully if you choose transformations.
    
3. Your sample size must be sufficiently large so that when the true model is fit to your data using lm(...), all p-values of X-variable terms (not including the intercept) found in the summary(...) are significant.


### True Model

Write out your final "true" model in mathematical form. Make sure it matches your code.

b0 <- 1.1
b1 <- -1
b2 <- 1
b3 <- 1/2
b4 <- -1/6
b5 <- -1/24
b6 <- 1/120
 
sigma <- 2.3

 ################################
 # You CANNOT change this part:
 errors <- rnorm(n, 0, sigma)
 ################################ 
 
Y <- exp(b0 + b1*X1 + b2*X6 + b3*X1*X6^2 + b4*X6^3 + b5*X1*X6^4 + b6*X6^5 + errors)

$$
  log(Y_i) = 1.1 - X_{1i} + X_{6i} + \frac{1}{2} X_{1i} {X_{6i}}^2 - \frac{1}{6} {X_{6i}}^3 - \frac{1}{24} X_{1i}{X_{6i}}^4 + \frac{1}{120} {X_{6i}}^5 + \epsilon_i \quad \text{where} \ \epsilon_i \sim N(0, 2.3^2)
$$

### The Code to Make the Data

```{r}
# original seed was 122
set.seed(112) #This ensures the randomness is the "same" everytime if you play the entire R-chunk as one entire piece of code. If you run lines separately, your data might not come out the same every time.

## To begin, decide on your sample size. (You may have to revise it later to ensure all values in your lm(...) are significant.)
n <- 300
  
## Then, create 10 X-variables using functions like rnorm(n, mean, sd), rchisq(n, df), rf(n, df1, df2), rt(n, df), rbeta(n, a, b), runif(n, a, b) or sample(c(1,0), n, replace=TRUE)...

X6 <- runif(n,0,4) 
X10 <- runif(n,0,4) 
X1 <- sample(0:1,n,replace = TRUE) 

X7 <- sample(c('John', 'Henry', 'Jessie', 'Sarah', 'Cory', 'Thor', 'Amelia', 'S C Kennedy', 'Big Max', 'Orion', 'Ferris', 'Kystystal', 'Zach', 'Jacqueline', 'Emily', 'Curious George', 'Alice', 'Francine', 'Johnny James Yogurt Jr', 'Bobo', 'Olivia', 'Marcel the Shell', '(─‿‿─)', 'Moose'),  size = n, replace = T)

X9 <- sample(rnorm(n, 9, 1.3) - seq(1, 3, length.out = n), n)/6
X2 <- 1/sample(rnorm(n, 0, 7) - seq(1, 3, length.out = n), n)/X9 + rnorm(n, -3, 1)
X9 <- -(X9 + X2 + rnorm(n, -3, 1)^2)
 
X8 <- rep(9, n)
X8[29] <- 1
 
X5 <- sample(seq(0.01, 10, length.out = n), n) + rnorm(n, 0, 0.2) + X2/3
X8 <- ifelse(X5 + rnorm(n, 1, 1) > 3.9, 1, 9)
 
X9 <- X9 + X8/9 + X2/10 
 
X7 <- paste0(X7, " - ", round(X9^2))
 
X3 <- runif(n, -1000, 1000)^X5

X4 <- 8.2 + ifelse(X9 > 2, 0   + rnorm(n, 0, .33), ifelse(X9 < -1, 1 + rnorm(n, 0, .15), ifelse(runif(n, 0, 1) > 0.5, 2  + rnorm(n, 0, .33), 3 + rnorm(n, 0, .33))))
X4 <- X4 - 2*log(X2 + 1000) + X6

a <- X2[199]
X2[199] <- X8[199]
X8[199] <- a

## Then, create betas, errors (by choosing sigma), and Y

b0 <- 1.1
b1 <- -1
b2 <- 1
b3 <- 1/2
b4 <- -1/6
b5 <- -1/24
b6 <- 1/120
 
# original version:
#b1 <- 1
# b2 <- 1/2
# b3 <- -1/6
# b4 <- -1/30
# b5 <- 1/120
# b6 <- -1

sigma <- 2.3

 ################################
 # You CANNOT change this part:
 errors <- rnorm(n, 0, sigma)
 ################################ 
 
#original:
#Y<-exp(b1*X1 + b3*X1^3 + b5*X1^5 + X3*b2*X1^2 + X3*b4*X1^4 + X3*b6 + errors + 1.1)

Y <- exp(b0 + b1*X1 + b2*X6 + b3*X1*X6^2 + b4*X6^3 + b5*X1*X6^4 + b6*X6^5 + errors)
 
 # You can include Y' or X' instead of Y or X if you wish.
 # Remember, only these functions are allowed when transforming
 # variables: 1/Y^2, 1/Y, log(Y), sqrt(Y), Y^2, Y^3, 1/X^2, 1/X, log(X), sqrt(X), X^2, X^3, X^4, X^5. 
 #########################################################
 # ILLEGAL: Y = (beta0 + beta1*X4)^2 + epsilon ###########
 #########################################################
 # Legal: sqrt(Y) = beta0 + beta1*X4^2 + epsilon #########
 #########################################################
 # You can only transform individual terms, not groups of terms.
 # And the beta's cannot be part of the transformation.

 # Load Your data into a data set:
 RBdata <- data.frame(Y, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10)
 
 #Now fit your model to make sure it comes out significant:


 mylm <- lm(log(Y) ~ X6 + X1 + I(X6^2):X1 + I(X6^3) + I(X6^4):X1 + I(X6^5))
 summary(mylm)  
 
# original:
# lm(log(Y)~X1+I(X1^2):X3+I(X1^3)+I(X1^4):X3+I(X1^5)+I(X3))
 
 #all p-values must be significant, except "(Intercept)"
 
```

```{r}
plot(log(Y) ~ X6, col = X1 + 2)
curve(b0 + b2*x + b4*x^3 + b6*x^5, add = T)
curve(b0 + b1 + b2*x + b3*x^2 + b4*x^3 + b5*x^4 + b6*x^5, add = T)

# The above curves are made similar to this:
curve(b0 + sin(x), add = T, lty = 2)
curve(b0 + sin(x) - cos(x), add = T, lty = 2)

# pairs(RBdata, col = X1 + 2)
# View(RBdata)
```
  
```{r}
# Once you are ready, run this code to write your data to a csv:
write.csv(RBdata, "data/RBdata_alt.csv", row.names = FALSE)
# The above code writes the dataset to your "current directory"
# To see where that is, use: getwd() in your Console.
# Find the data set and upload it to I-Learn.
```


 

 